# Quality Amplification Workflow

Complete automated system for code quality improvement and learning from successful projects.

## ğŸ¯ Overview

This workflow combines three powerful systems:
1. **Code Mirror** - Analyzes code quality against elite repositories
2. **Self-Improving** - Learns patterns from successful GitHub projects  
3. **Quality Pipeline** - Automated improvement workflow

## ğŸ“¦ Quick Start

```bash
# Full quality check and improvement
npm run quality

# Individual commands
npm run mirror   # Code quality analysis only
npm run learn    # Learn from GitHub projects
npm run improve  # Run complete pipeline
```

## ğŸš€ What Each Command Does

### `npm run mirror`
- Scans your TypeScript codebase
- Analyzes 4 categories: error handling, type safety, performance, architecture
- Generates quality scores (0-100)
- Identifies gaps and suggests fixes
- Outputs: `logs/mirror-report.md`

### `npm run learn`
- Searches GitHub for successful repositories
- Extracts patterns in positioning, pricing, features, architecture
- Updates knowledge base with findings
- Provides confidence-scored recommendations
- Outputs: `logs/self-improve-report.md`

### `npm run improve`
- Runs Code Mirror analysis
- Learns from successful projects
- Cross-references findings
- Applies automatic fixes (when safe)
- Generates PR templates
- Outputs: `logs/quality-pipeline-report.json`

## ğŸ“Š Quality Dashboard

Access the visual dashboard at: `http://localhost:5173/quality`

**Features:**
- Real-time quality scores
- Category breakdowns (error handling, type safety, etc.)
- Learned patterns from elite repos
- Applied vs suggested improvements
- Quality history tracking
- Next steps recommendations

## ğŸ”„ Automated Workflow

The system can run automatically via GitHub Actions:

```bash
# Manual trigger
gh workflow run self-improve.yml

# Runs automatically every Monday at 9 AM UTC
```

## ğŸ“ File Structure

```
scripts/
â”œâ”€â”€ run-mirror.ts         # Code quality analyzer
â”œâ”€â”€ run-self-improve.ts   # GitHub learning system  
â””â”€â”€ quality-pipeline.ts   # Complete workflow

src/
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ code-mirror.ts         # Analysis engine
â”‚   â”œâ”€â”€ self-improve.ts        # Learning engine
â”‚   â”œâ”€â”€ mirror-standards.json  # Quality standards
â”‚   â””â”€â”€ knowledge-base/        # Learned patterns
â”‚       â”œâ”€â”€ positioning.md
â”‚       â”œâ”€â”€ pricing.md
â”‚       â”œâ”€â”€ features.md
â”‚       â””â”€â”€ architecture.md
â””â”€â”€ pages/
    â””â”€â”€ QualityDashboard.tsx   # Visual dashboard

logs/
â”œâ”€â”€ mirror-report.md              # Code analysis
â”œâ”€â”€ self-improve-report.md        # Learning results
â”œâ”€â”€ quality-pipeline-report.json  # Combined results
â””â”€â”€ quality-pr-template.md        # PR template
```

## ğŸ“ Knowledge Base

Auto-updated markdown files that capture learned patterns:

- **positioning.md** - How successful projects communicate value
- **pricing.md** - Monetization strategies that work
- **features.md** - Priority features for adoption
- **architecture.md** - Code patterns that scale

Use these as reference when making product decisions!

## ğŸ”§ Configuration

Edit pipeline settings in `scripts/quality-pipeline.ts`:

```typescript
const config = {
  targetDir: "src",           // Directory to analyze
  maxFiles: 30,               // Max files to scan
  learningNiche: "React TS",  // GitHub search niche
  minStars: 2000,             // Min repo stars
  qualityThreshold: 70,       // Pass/fail threshold
  autoApplyFixes: false,      // Auto-fix safe issues
  generatePR: false,          // Create PR branch
};
```

## ğŸ“ˆ Interpreting Scores

- **90-100**: Excellent - Elite level code
- **75-89**: Good - Professional quality
- **60-74**: Acceptable - Room for improvement
- **<60**: Needs work - Priority fixes required

## ğŸ¯ Using Learned Patterns

When patterns are discovered with high confidence (>70%):
1. Review the pattern in knowledge base
2. Check evidence from source repos
3. Apply to your codebase
4. Track improvement in next run

## ğŸš¨ Critical Issues

Pipeline fails if:
- Critical issues found (severity: critical)
- Quality score below threshold
- Learning system errors

Fix these immediately before merging PRs.

## ğŸ”„ Continuous Improvement

Recommended workflow:
1. Run `npm run quality` before major features
2. Review dashboard weekly
3. Apply high-confidence patterns monthly
4. Learn from new niches quarterly

## ğŸ“š Example Output

**Code Analysis:**
- Average Score: 99/100 âœ…
- Files Analyzed: 20
- Critical Issues: 0
- Files Needing Work: 0

**Learning Results:**
- Patterns Discovered: 7
- High Confidence: 4
- Top Pattern: "TypeScript-first development" (85% confidence)

**Improvements:**
- Auto-Applied: 0
- Suggested: 1
- Next: "Apply 4 high-confidence patterns"

## ğŸ¨ Dashboard Features

**Overview Tab:**
- Quality breakdown by category
- Progress bars with color coding
- Next steps checklist

**Patterns Tab:**
- Discovered success patterns
- Confidence scores
- Source repositories

**Improvements Tab:**
- Applied fixes âœ…
- Suggested improvements ğŸ’¡
- Learning recommendations

**History Tab:**
- Score trends over time
- Visual progress tracking

## ğŸ’¡ Pro Tips

1. **Before big refactors:** Run mirror to establish baseline
2. **Stuck on architecture?** Check knowledge base for patterns
3. **Need validation?** Compare your patterns to learned ones
4. **Want faster learning?** Use GitHub token for higher rate limits
5. **Track team progress:** Share dashboard URL in standups

## ğŸ”— Integration

Works seamlessly with:
- GitHub Actions (automated runs)
- Git workflow (PR templates)
- VS Code (reports in logs/)
- Your existing CI/CD

## ğŸ“ Troubleshooting

**No patterns found?**
- Check GitHub token is valid
- Try broader niche search
- Lower min-stars threshold

**Low quality score?**
- Review specific gaps in mirror report
- Apply suggested fixes one by one
- Re-run to track improvement

**Dashboard not loading?**
- Run pipeline first to generate data
- Check logs/ directory exists
- Verify JSON report is valid

## ğŸ¯ Success Metrics

Track these over time:
- Overall quality score trend
- Critical issues count
- Patterns applied count
- Time to fix issues
- Community adoption of your patterns

---

**Built for:** Solo founders and small teams
**Philosophy:** Learn from the best, automate the rest
**Goal:** Elite-level code quality with zero infrastructure costs
